library(rpart)
library(rpart.plot)
library(ggplot2)
library(randomForest)
library(dplyr)


#                 LISTA FINAL DE ESTATISTICA COMPUTACIONAL

#  EXERCICIO 1 =================================================================

# A) ---------------------------------------------------------------------------

diabetes <- read.csv('diabetes.txt',sep = ';')
str(diabetes)

n <- round(0.8*nrow(diabetes))
indices_treino <- sample(1:nrow(diabetes),size = n, replace = FALSE)

treino <- diabetes[indices_treino,]
teste <- diabetes[-indices_treino,]

diabetes$Diabetic <- as.factor(diabetes$Diabetic)
treino$Diabetic <- as.factor(treino$Diabetic)
teste$Diabetic <- as.factor(teste$Diabetic)

ggplot(diabetes, aes(x = as.factor(Diabetic), y = PlasmaGlucose, 
                     fill = as.factor(Diabetic))) +
  geom_boxplot() +
  theme_minimal()

ggplot(diabetes, aes(x = BMI, fill = as.factor(Diabetic))) +
  geom_histogram(alpha = 0.7) +
  theme_minimal()

ggplot(diabetes, aes(x = Age, fill = as.factor(Diabetic))) +
  geom_histogram(alpha = 0.7) +
  theme_minimal()

ggplot(diabetes, aes(x = Age, y = BMI, color = as.factor(Diabetic))) +
  geom_point(alpha = 0.6) +
  theme_minimal()

'''
ConcentraÃ§Ã£o de Glicose no Plasma: Os pacientes com diabetes tendem a ter 
valores mais altos de glicose em comparaÃ§Ã£o aos pacientes sem diabetes.
Ãndice de Massa Corporal (IMC): Observa-se que pacientes diabÃ©ticos apresentam 
IMC mais alto, sugerindo uma possÃ­vel relaÃ§Ã£o entre peso corporal e diabetes.
DistribuiÃ§Ã£o de Idade: A idade mÃ©dia dos pacientes com diabetes parece ser maior
do que a dos pacientes sem diabetes, indicando que a idade pode ser um fator 
relevante.
'''

# B) ---------------------------------------------------------------------------

# Modelo de Ã¡rvore de decisÃ£o usando o conjunto de dados de treinamento
modelo_arvore <- rpart(formula = Diabetic~ ., data = treino, method = "class") 

# Plot da Ã¡rvore de decisÃ£o
rpart.plot(modelo_arvore,extra = 101)

# FunÃ§Ã£o para classificar um paciente com base nas regras da Ã¡rvore
classificar_paciente <- function(Pregnancies, PlasmaGlucose, 
                                 DiastolicBloodPressure, TricepsThickness, 
                                 SerumInsulin, BMI, DiabetesPedigree, Age) {
  if(Pregnancies >= 2){
    if(BMI >= 22){
      if(SerumInsulin >= 52){
        if(Age >= 36){
          return('Paciente tem diabetes!')
        }
        else{
          if(Age < 24){
            return('Paciente tem diabetes!')
          }
          else{
            if(Age >= 27){
              return('Paciente tem diabetes!')
            }  
          }
        }
      }
      else{
        if(Age >= 36){
          return('Paciente tem diabetes!')
        }
      }
    }
  }
  return('Paciente nÃ£o tem diabetes!')
}

# Exemplo de uso
classificar_paciente(Pregnancies = 3, PlasmaGlucose = 150, 
                     DiastolicBloodPressure = 80, 
                     TricepsThickness = 20, SerumInsulin = 60, BMI = 25, 
                     DiabetesPedigree = 0.5, Age = 40)

# PrevisÃ£o para o conjunto de teste
previsao <- predict(modelo_arvore,newdata = teste,type = "class")

# CÃ¡lculo da acurÃ¡cia
mean(previsao == teste$Diabetic)

# C) ---------------------------------------------------------------------------

# Crie o modelo de floresta aleatÃ³ria
modelo_floresta <- randomForest(Diabetic ~ ., data = treino, ntree = 100)
# ntree define o nÃºmero de Ã¡rvores

# FaÃ§a previsÃµes para o conjunto de teste
previsao_floresta <- predict(modelo_floresta, newdata = teste)

# Calcular a acurÃ¡cia
acuracia_mf <- mean(previsao_floresta == teste$Diabetic)

# D) ---------------------------------------------------------------------------

# Probabilidades do modelo de Ã¡rvore de decisÃ£o
probabilidades_ad <- predict(modelo_arvore, newdata = teste, type = "prob")

# Verificando as probabilidades para o diagnÃ³stico "Diabetic" (com diabetes)
prob_arvore <- probabilidades_ad[, "1"] 

# Exibindo as primeiras probabilidades
head(prob_arvore)

# Probabilidades do modelo de floresta aleatÃ³ria
probabilidades_mf <- predict(modelo_floresta, newdata = teste, type = "prob")

# Verificando as probabilidades para o diagnÃ³stico "Diabetic" (com diabetes)
prob_floresta <- probabilidades_mf[,"1"]

# Exibindo as primeiras probabilidades
head(prob_floresta)

# Comparando as previsÃµes de ambos os modelos com os valores reais
acuracia_arvore <- mean(previsao == teste$Diabetic)
acuracia_floresta <- mean(previsao_floresta == teste$Diabetic)

# Exibindo as acurÃ¡cias
cat("AcurÃ¡cia do modelo de Ã¡rvore de decisÃ£o:", acuracia_arvore, "\n")
cat("AcurÃ¡cia do modelo de floresta aleatÃ³ria:", acuracia_floresta, "\n")

# E) ---------------------------------------------------------------------------

'''
ApÃ³s treinar os modelos de Ã¡rvore de decisÃ£o e floresta aleatÃ³ria, observamos 
que a Ã¡rvore de decisÃ£o apresenta uma acurÃ¡cia de 90%, enquanto a floresta 
aleatÃ³ria alcanÃ§a 93%. A Ã¡rvore de decisÃ£o Ã© fÃ¡cil de interpretar, mas tende a 
overfit se os dados forem muito complexos. Por outro lado, a floresta aleatÃ³ria 
oferece uma soluÃ§Ã£o mais robusta e precisa, especialmente quando hÃ¡ interaÃ§Ãµes 
complexas entre as variÃ¡veis, mas sua interpretabilidade Ã© mais limitada.
'''

#  EXERCICIO 2 =================================================================

# A) ---------------------------------------------------------------------------

cerebelo <- read.csv('cerebelo.csv')

# Primeiro grÃ¡fico: Peso do Cerebelo vs Peso do Corpo
ggplot(data = cerebelo, aes(y = Cerebellum_g,x = Body_g)) +
  geom_point() +
  theme_minimal()

# Segundo grÃ¡fico: Log do Peso do Cerebelo vs Log do Peso do Corpo
ggplot(data = cerebelo, aes(y = Log_cerebellum,x = Log_body)) +
  geom_point() +
  theme_minimal()

'''
O primeiro grÃ¡fico de dispersÃ£o mostra o peso do cerebelo em relaÃ§Ã£o ao peso do 
corpo. Parece que, conforme o peso do corpo aumenta, o peso do cerebelo tambÃ©m 
tende a aumentar, embora haja alguma variabilidade, possivelmente devido a dife-
renÃ§as especÃ­ficas entre as espÃ©cies.

O segundo grÃ¡fico, com valores transformados em logaritmo, mostra uma relaÃ§Ã£o 
mais linear entre as duas variÃ¡veis. A transformaÃ§Ã£o logarÃ­tmica frequentemente
ajuda a linearizar relaÃ§Ãµes onde uma variÃ¡vel cresce exponencialmente em relaÃ§Ã£o
a outra. Nesse caso, isso sugere que o peso do cerebelo escala de maneira aproxi
madamente proporcional ao peso do corpo em uma escala logarÃ­tmica, destacando 
uma relaÃ§Ã£o mais previsÃ­vel entre as espÃ©cies.

Essa comparaÃ§Ã£o revela que o uso de escalas logarÃ­tmicas pode ajudar a normali-
zar dados com diferentes escalas, permitindo observar tendÃªncias subjacentes com
mais clareza.
'''

# B) ---------------------------------------------------------------------------

cor(cerebelo$Cerebellum_g,cerebelo$Body_g)

# C) ---------------------------------------------------------------------------

cor(cerebelo$Log_cerebellum,cerebelo$Log_body)

# D) ---------------------------------------------------------------------------

'''
CorrelaÃ§Ã£o entre o Peso do Cerebelo e o Peso do Corpo: O coeficiente de correla-
Ã§Ã£o de aproximadamente 0,35 indica uma correlaÃ§Ã£o positiva, mas fraca, entre o 
peso do cerebelo e o peso do corpo. Isso significa que, embora exista uma 
tendÃªncia de o peso do cerebelo aumentar com o peso do corpo, a relaÃ§Ã£o Ã© rela-
tivamente dispersa e menos consistente.

CorrelaÃ§Ã£o entre o Logaritmo do Peso do Cerebelo e o Logaritmo do Peso do Corpo:
O coeficiente de correlaÃ§Ã£o de aproximadamente 0,95 para os valores log-transfor
mados indica uma correlaÃ§Ã£o positiva forte entre o logaritmo do peso do cerebelo
e o logaritmo do peso do corpo. Essa relaÃ§Ã£o muito prÃ³xima de 1 sugere que, em 
uma escala logarÃ­tmica, o peso do cerebelo aumenta de forma quase proporcional 
ao peso do corpo, refletindo uma relaÃ§Ã£o muito mais consistente e linear.

A transformaÃ§Ã£o logarÃ­tmica revela uma relaÃ§Ã£o mais clara e linear entre as duas
variÃ¡veis. Isso sugere que a escala logarÃ­tmica Ã© mais adequada para descrever 
como o peso do cerebelo varia em relaÃ§Ã£o ao peso do corpo, especialmente quando 
as variÃ¡veis apresentam crescimento nÃ£o-linear ou diferenÃ§as de escala 
considerÃ¡veis.
'''

# E) ---------------------------------------------------------------------------

modelo <- lm(data = cerebelo, formula = Log_cerebellum ~ Log_body)

summary(modelo)

'''
A equaÃ§Ã£o da reta de regressÃ£o para os valores log-transformados Ã© dada por:

Log_cerebellum = âˆ’2.15741 + 0.78278 Ã— Log_body

> summary(modelo)

Call:
lm(formula = Log_cerebellum ~ Log_body, data = cerebelo)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.58221 -0.16055  0.00174  0.13638  0.56574 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept) -2.15741    0.24449  -8.824 7.53e-07 ***
Log_body     0.78278    0.07213  10.852 6.91e-08 ***
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

Residual standard error: 0.2991 on 13 degrees of freedom
Multiple R-squared:  0.9006,	Adjusted R-squared:  0.8929 
F-statistic: 117.8 on 1 and 13 DF,  p-value: 6.912e-08

Teste de HipÃ³teses: Ambos os coeficientes tÃªm valoresğ‘muito pequenos (7.53e-07
para o intercepto e 6.91e-08 para Log_body),o que indica que sÃ£o estatisticamen-
te significativos a nÃ­veis de significÃ¢ncia comuns (p < 0.001). Esses resultados 
sugerem que hÃ¡ evidÃªncias para uma relaÃ§Ã£o significativa entre o log do peso do 
corpo e o log do peso do cerebelo.

'''

# GrÃ¡fico de dispersÃ£o com os dados transformados em log com a reta de regressÃ£o
ggplot(data = cerebelo, aes(y = Log_cerebellum, x = Log_body)) +
  geom_point() +
  geom_smooth(method = 'lm', color = "blue") +
  theme_minimal()
  
# F) ---------------------------------------------------------------------------

hist(modelo$residuals)

shapiro.test(modelo$residuals)

'''
InterpretaÃ§Ã£o dos Resultados:
Valor-p: O valor-p de 1 indica que nÃ£o hÃ¡ evidÃªncias suficientes para rejeitar a
hipÃ³tese nula de normalidade dos resÃ­duos.Isso significa que,com base nos dados,
os resÃ­duos podem ser considerados normalmente distribuÃ­dos.

ConclusÃ£o: Como o valor-p Ã© significativamente maior que um nÃ­vel comum de signi
ficÃ¢ncia (como 0,05), podemos concluir que os resÃ­duos seguem uma distribuiÃ§Ã£o 
normal, o que Ã© um bom indicativo para a validade do modelo de regressÃ£o linear.
A suposiÃ§Ã£o de normalidade dos resÃ­duos Ã© importante porque reforÃ§a que o modelo
fornece estimativas confiÃ¡veis e que as inferÃªncias estatÃ­sticas (como interva-
los de confianÃ§a e testes de hipÃ³tese) sÃ£o vÃ¡lidas.
'''  

# G) ---------------------------------------------------------------------------

# Define o peso do corpo em gramas
peso <- 100000

# Converte o peso do corpo para a escala logarÃ­tmica (base 10)
log_peso <- log10(peso)

# Coeficientes do modelo de regressÃ£o
b <- -2.15741
a <- 0.78278

# Calcula o logaritmo do peso do cerebelo usando a equaÃ§Ã£o de regressÃ£o
log_cerebelo <- a * log_peso + b

# Converte de volta para a escala original (gramas)
celebelo_peso <- 10^log_cerebelo
celebelo_peso

'''
A previsÃ£o para o peso do cerebelo de uma espÃ©cie que pesa 100.000g 
Ã© aproximadamente 57,1 g
'''

#  EXERCICIO 3 =================================================================

# A) ---------------------------------------------------------------------------

# Carrega o conjunto de dados
olive <- read.csv('olive.txt')

# Padroniza os dados e salvar no objeto 'dados_padronizados'
dados_padronizados <- scale(olive[,-1]) # Remove a coluna nÃ£o numÃ©rica

# Visualiza a estrutura dos dados padronizados
str(dados_padronizados)

# B) ---------------------------------------------------------------------------

# Cria o modelo K-means com k = 3
clusterizacao <- kmeans(dados_padronizados, centers = 3)

# Adiciona o vetor de clusters ao conjunto de dados como uma variÃ¡vel categÃ³rica
olive$cluster_k3 <- as.factor(clusterizacao$cluster)

# VisualizaÃ§Ã£o do data frame com a nova variÃ¡vel cluster_k3
head(olive)

# GrÃ¡fico de barras com K = 3
ggplot(olive, aes(x = cluster_k3, fill = region)) +
  geom_bar() +
  theme_minimal()

'''
ComentÃ¡rios sobre os resultados:
Utilizando k = 3, podemos perceber pelo grÃ¡fico que o cluster 2 Ã© dominada pela 
regiÃ£o Southern Italy e o cluster 1 Ã© dominada pela regiÃ£o Northern Italy, 
oque indica forte correlaÃ§Ã£o entre a variÃ¡vel region e as caracterÃ­sticas dos 
dados que formam o cluster. Isso poderia sugerir que o K-means foi capaz de 
identificar agrupamentos naturais baseados em uma combinaÃ§Ã£o de variÃ¡veis 
numÃ©ricas, refletindo diferentes padrÃµes regionais. AlÃ©m disso, o terceiro 
cluster estÃ¡ dividido quase igualmente entre as regiÃµes Northern Italy, Southern
Italy e Sardinia. Isso pode indicar que este cluster representa um conjunto mais
heterogÃªneo de observaÃ§Ãµes, onde as caracterÃ­sticas numÃ©ricas nÃ£o sÃ£o tÃ£o 
exclusivas de uma regiÃ£o especÃ­fica
'''

# C) ---------------------------------------------------------------------------

# Cria o modelo K-means com k = 4
clusterizacao <- kmeans(dados_padronizados, centers = 4)

# Adiciona o vetor de clusters ao conjunto de dados como uma variÃ¡vel categÃ³rica
olive$cluster_k4 <- as.factor(clusterizacao$cluster)

# VisualizaÃ§Ã£o do data frame com a nova variÃ¡vel cluster_k4
head(olive)

# GrÃ¡fico de barras com K = 4
ggplot(olive, aes(x = cluster_k4, fill = region)) +
  geom_bar() +
  theme_minimal()

'''
ComentÃ¡rios sobre os resultados:
Ao utilizar k = 4, houve uma mudanÃ§a significativa na distribuiÃ§Ã£o dos clusters 
em comparaÃ§Ã£o com o modelo de 3 clusters. Cada cluster agora Ã© quase exclusivo 
de uma Ãºnica regiÃ£o, o que indica que as observaÃ§Ãµes dentro de cada cluster 
compartilham caracterÃ­sticas muito semelhantes que estÃ£o mais alinhadas com os 
padrÃµes encontrados em uma regiÃ£o especÃ­fica. Essa mudanÃ§a sugere que, ao aumen-
tar o nÃºmero de clusters, o modelo foi capaz de capturar melhor as nuances 
regionais dos dados.
'''

# Cria o modelo K-means com k = 5
clusterizacao <- kmeans(dados_padronizados, centers = 5)

# Adiciona o vetor de clusters ao conjunto de dados como uma variÃ¡vel categÃ³rica
olive$cluster_k5 <- as.factor(clusterizacao$cluster)

# VisualizaÃ§Ã£o do data frame com a nova variÃ¡vel cluster_k5
head(olive)

# GrÃ¡fico de barras com K = 5
ggplot(olive, aes(x = cluster_k5, fill = region)) +
  geom_bar() +
  theme_minimal()

'''
ComentÃ¡rios sobre os resultados:
Semelhante ao k = 4 quando usamos k = 5, a distribuiÃ§Ã£o dos clusters continua 
semelhante ao modelo com k = 4, ou seja, cada cluster permanece quase exclusivo 
de uma Ãºnica regiÃ£o. Isso indica que o aumento do nÃºmero de clusters nÃ£o alterou 
significativamente a separaÃ§Ã£o das observaÃ§Ãµes de acordo com a variÃ¡vel region.
'''

# ==============================================================================